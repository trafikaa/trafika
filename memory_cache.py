import time
import socket
import gradio as gr
from dotenv import load_dotenv
import os

from redis import Redis
from langchain_core.globals import set_llm_cache
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_community.cache import RedisCache
from langchain_core.caches import InMemoryCache as CoreInMemoryCache
from langchain_openai import ChatOpenAI

# âœ… .env íŒŒì¼ ë¡œë“œ
load_dotenv(override=True)

# âœ… í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
OPENAI_API_KEY = os.getenv("API2")
MODEL_NAME = os.getenv("OPENAI_DEFAULT_MODEL")
REDIS_HOST = os.getenv("REDIS_HOST")
REDIS_PASSWORD = os.getenv("REDIS_PWD")
REDIS_PORT = int(os.getenv("REDIS_PORT"))

class InvestmentChatBot:
    """
    íˆ¬ì êµìœ¡ ì „ë¬¸ê°€ ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ” LangChain ê¸°ë°˜ ì±—ë´‡
    Redis ìºì‹œë¥¼ í†µí•´ LLM ì‘ë‹µ ì†ë„ í–¥ìƒ
    """

    def __init__(self):
        self.system_prompt = """ë‹¹ì‹ ì€ íˆ¬ì êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ë©°, ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ íˆ¬ì êµìœ¡ì„ ì œê³µí•©ë‹ˆë‹¤:
        1. ê°œë… ì„¤ëª… â†’ 2. ìƒí˜¸ì‘ìš© í€´ì¦ˆ â†’ 3. í”¼ë“œë°± ì œê³µ
        ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ë§¥ë½ì— ë§ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”."""

        self._init_cache()

        # LangChain ê¸°ë°˜ OpenAI LLM ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model=MODEL_NAME,
            temperature=0.3,
            streaming=True,
            api_key=OPENAI_API_KEY
        )

    def _init_cache(self):
        """
        Redis ìºì‹œ ì—°ê²° ì‹œë„, ì‹¤íŒ¨ ì‹œ ì¸ë©”ëª¨ë¦¬ ìºì‹œë¡œ ëŒ€ì²´
        """
        try:
            if REDIS_HOST and REDIS_PASSWORD:
                redis_client = Redis(
                    host=REDIS_HOST,
                    port= 17159,
                    password=REDIS_PASSWORD,
                    decode_responses=True
                )
                redis_client.ping()
                set_llm_cache(RedisCache(redis_client))
            else:
                # set_llm_cache(CoreInMemoryCache())
                print("Redis ì—°ê²° ì‹¤íŒ¨: ì¸ë©”ëª¨ë¦¬ ìºì‹œë¡œ ì „í™˜í•´ì£¼ì„¸ìš”.")
        except:
            # set_llm_cache(CoreInMemoryCache())
            print("Redis ì—°ê²° ì‹¤íŒ¨: ì¸ë©”ëª¨ë¦¬ ìºì‹œë¡œ ì „í™˜í•´ì£¼ì„¸ìš”.")

    def _convert_to_langchain_messages(self, gradio_history):
        """
        Gradio history â†’ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        """
        messages = [SystemMessage(content=self.system_prompt)]
        for user_msg, bot_msg in gradio_history:
            if user_msg:
                messages.append(HumanMessage(content=user_msg))
            if bot_msg:
                messages.append(AIMessage(content=bot_msg))
        return messages

    def stream_response(self, user_input: str, gradio_history: list):
        """
        LangChainì˜ Streaming APIë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ì‘ë‹µ ìƒì„±
        """
        messages = self._convert_to_langchain_messages(gradio_history)
        messages.append(HumanMessage(content=user_input))

        collected = []
        for chunk in self.llm.stream(messages):
            if chunk.content:
                collected.append(chunk.content)
                yield ''.join(collected)
                time.sleep(0.02)

    def get_history_length(self, gradio_history):
        """
        í˜„ì¬ ëŒ€í™” ë‚´ì—­ ê¸¸ì´ ë°˜í™˜
        """
        return len(gradio_history)


# âœ… Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±
def create_interface():
    bot = InvestmentChatBot()

    with gr.Blocks(theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ“Š íˆ¬ì í•™ìŠµ ì±—ë´‡")
        gr.Markdown("íˆ¬ì ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì±—ë´‡ì´ ì¹œì ˆí•˜ê²Œ êµìœ¡í•´ ë“œë¦½ë‹ˆë‹¤.")

        with gr.Row():
            with gr.Column(scale=4):
                chatbot = gr.Chatbot(
                    label="ëŒ€í™” ë‚´ìš©",
                    height=500,
                    bubble_full_width=False
                )
            with gr.Column(scale=1):
                status = gr.Textbox(label="ìƒíƒœ", value="ëŒ€í™” ê¸°ë¡: 0ê°œ", interactive=False)

        user_input = gr.Textbox(
            label="ë©”ì‹œì§€ ì…ë ¥",
            placeholder="ì˜ˆ: 'ETFê°€ ë­ì˜ˆìš”?'",
            lines=2
        )

        with gr.Row():
            submit_btn = gr.Button("ì „ì†¡", variant="primary")
            clear_btn = gr.Button("ì´ˆê¸°í™”", variant="secondary")

        def respond(message, history):
            if not message.strip():
                return history, "", f"ëŒ€í™” ê¸°ë¡: {bot.get_history_length(history)}ê°œ"
            history = history + [(message, "")]
            full_response = ""
            for chunk in bot.stream_response(message, history[:-1]):
                full_response = chunk
                history[-1] = (message, full_response)
                yield history, "", f"ëŒ€í™” ê¸°ë¡: {bot.get_history_length(history)}ê°œ"

        def clear_chat():
            return [], "", "ëŒ€í™” ê¸°ë¡: 0ê°œ"

        user_input.submit(respond, [user_input, chatbot], [chatbot, user_input, status])
        submit_btn.click(respond, [user_input, chatbot], [chatbot, user_input, status])
        clear_btn.click(clear_chat, outputs=[chatbot, user_input, status])

    return demo


# âœ… ì‹¤í–‰ë¶€
if __name__ == "__main__":
    if not OPENAI_API_KEY:
        raise EnvironmentError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

    demo = create_interface()

    # ì‚¬ìš© ê°€ëŠ¥í•œ í¬íŠ¸ ìë™ í• ë‹¹
    def find_free_port():
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.bind(('', 0))
            return s.getsockname()[1]

    demo.launch(
        server_name="127.0.0.1",
        server_port=find_free_port(),
        share=True,
        show_error=True
    )